---
title: "Helium"
author: "Thomas de Marchin"
date: "January 2022"
output: 
  html_document:
    number_sections: true
---

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = T, warning = F, message = F, cache = F, out.width = '100%')
```

**Thomas is Senior Data Scientist at Pharmalex. He is passionate about the incredible possibility that blockchain technology offers to make the world a better place. You can contact him on [Linkedin](https://www.linkedin.com/in/tdemarchin/) or [Twitter](https://twitter.com/tdemarchin).**

**Milana is Data Scientist at Pharmalex. She is passionate about the power of analytical tools to discover the truth about the world around us and guide decision making. You can contact her on [Linkedin](https://www.linkedin.com/in/mfilatenkova/).**

# Introduction

***What is the Blockchain:*** A blockchain is a growing list of records, called blocks, that are linked together using cryptography. It is used for recording transactions, tracking assets, and building trust between participating parties. Primarily known for Bitcoin and cryptocurrencies application, Blockchain is now used in almost all domains, including supply chain, healthcare, logistic, identity management... Some blockchains are public and can be accessed from everyone while some are private. Hundreds of blockchains exist with their own specifications and applications: Bitcoin, Ethereum, Tezos...  
***What is Helium:*** Helium is a decentralized wireless infrastructure. It is a blockchain that leverages a decentralized global network of Hotspots. A hotspot is a sort of a modem with an antenna, to provide long-range connectivity (it can reach 200 times farther than conventional Wi-Fi!) between wireless “internet of things” (IoT) devices, it can be environmental sensors to monitor air quality or for agricultural purpose, it can also be localisation sensors to track bike fleets. People are incentivized to install hotspots and participate to the network by earning Helium tokens, which can be bought and sold like any other cryptocurrency. To learn more about Helium, read this excellent [article](https://www.nytimes.com/2022/02/06/technology/helium-cryptocurrency-uses.html).

***What is R:*** R language is widely used among statisticians and data miners for developing data analysis software. 

This is the third article on a series of articles on interaction with blockchains using R. Part I focuses on some basic concepts related to blockchain, including how to read the blockchain data. Part II focuses on how to get NFTs data transactions and how to visualise it. If you haven't read them, I strongly encourage you to do so to get familiar with the tools and terminology we use in this second article: [Part I](https://towardsdatascience.com/data-science-on-blockchain-with-r-afaf09f7578c) and [Part II](https://towardsdatascience.com/data-science-on-blockchain-with-r-part-ii-tracking-the-nfts-c054eaa93fa). 

I love the Helium project because it is not just about finance like many other blockchain projects but it has real-world applications. It solves problems that exist for people outside the crypto world and that is awesome.
Looking at Helium data is a whole new step. It is not only a simple curiosity, I believe people needs access to metrics and statistics to take good decisions and they might find our work useful. So coming back to your question, our present goal in regard to Helium network is to visualise the growth of the network and to quantify its usage. This time, it is a bit harder to get the data because we need all historical data for all hotspots so that means we need to retrieve the full blockchain, which is about several TB of data.

We will put an emphasis on visualisation. I like numbers and summary statistics but there is nothing better than a good graph to communicate a message.

To fetch the data, we can:

  - Set-up an ETL
  - Download data from the Metabase Dewi ETL
  - Use the API
  - Download data dump from http://18.212.212.108:8000/ 



# Data

```{r}
# First, let's load a few useful packages
library(knitr)
library(tidyverse)
library(data.table)
library(ggplot2)
library(gganimate)
library(hexbin)
library(h3)
library(lubridate)
library(sp)
library(rworldmap)
library(rayshader)
```

When you work with big dataset, it can get (very) slow. Here are two tricks to speed-up a bit: (1) work with packages/function adapted to handle large dataset and (2) try to keep only the data you need to save memory.
We use here the *fread* from the *data.table* package is similar to *read.table* but it is much faster, more convenient and it takes care of decompressing files automatically.

# Hotspot statistics and visualisation

First thing we need is information about the hotspots such as their location and when they were seen for the first time by the network.

For the location, Helium use a system called the Uber's H3 index. H3 is a geospatial indexing system using a hexagonal grid, with higher resolutions covering a larger area, and the smallest resolution covering centimeters of the earth. Helium uses the resolution 8. To give an idea, with this resolution, the earth is covered by 691,776,122 hexagons (see [here](https://h3geo.org/docs/core-library/restable/)). In order to process the data, we convert the H3 into lat/lng using the *H3* package. 

```{r}
### Retrieve info on the gateway
dataHotspots <- fread(file = "data/gateway_inventory_01213771.csv.gz") %>%
  select(address, owner, first_timestamp, location_hex) %>%
  rename(hotspot = address,
         firstDate = first_timestamp) %>%
  filter(location_hex != "", # remove hotspots without location
         firstDate != as.POSIXct("1970-01-01 00:00:00", tz = "UTC")) # a few hotspots appears to have been installed in 1970. This is obviously a mistake in the data base.

dataHotspots <- dataHotspots %>%
  mutate(data.frame(h3_to_geo(location_hex))) # get the centers of the given H3 indexes
```

## Number of hotspot per owner

First info we can get is the number of hotspot per owner. 
```{r}
nHotspotsPerOwner <- dataHotspots %>% 
  group_by(owner) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) 

nHotspotsPerOwner %>%
  slice(1:10) %>%
  kable(caption = "Table 1: Number of hotspot per owner.")
```

If we plot an histogram of the count, it will be difficult to visualize anything. Indeed, the distribution is hyper skewed. Most owner have only 1-2 hotspots but some have more than 100, up to 2000 (who are they?). To visualize the distribution, we will here restrict the the number of owner with less than 100 hotspots.
```{r, out.width = '75%'}
ggplot(filter(nHotspotsPerOwner, count <= 100), aes(count)) +
   geom_histogram(bins = 100) +
   scale_y_continuous(trans='log10') 
```

## Growth of the network in terms of number of hotspots

We can also visualize the growth of the network in terms of number of hotspots. We see three phases: (1) a slow linear increase, (2) and exponential increase in the middle of 2021 followed by (3) a fast linear increase. My opinion is that the exponential increase could have continued a bit more but Hotspot supplies have been limited by the world chips shortage following the Covid pandemy. To give an idea, there was 6 months between my hotspot order and its delivery. 

```{r, out.width = '75%'}
nHotspotsPerDate <- dataHotspots %>% 
  group_by(firstDate, lat, lng) %>%
  summarise(count = n()) 

ggplot(nHotspotsPerDate, aes(x = firstDate, y = cumsum(count))) +
  geom_line() +
  labs(title = "Growth of the hotspots", 
       y = "Total number of hotspot",
       x = "Date") +
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE),
                     breaks = seq(0, 5*10^5, length = 6))
```


Now we can visualize the size of the network in terms of hotspots. We start by creating an empty world map and we then overlay the hotspot data. Plotting all the individual hotspot on a map will just be too much (there are more than 500k hotspots), the data is clearer to plot and interpret once it is summarised. We chose here to bin the hotspots into hexagons ([function here](https://stackoverflow.com/questions/39296198/operation-between-stat-summary-hex-plots-made-in-ggplot2/39300644)) and we can then plot them using geom_hex(). 

We see that most hotspots are located in North America, Europe and Asia, mostly in big cities. There are practically no hotspot in Africa, Russia and very little in South America. Surprisingly, we see a few hotspots in the middle of the ocean. It could be a data issue or cheating: as the hotspot location has an impact on the reward, some owners try to spoof the system. 

```{r}
# create an empty world map
world <- map_data("world")
map <- ggplot() +
  geom_map(
    data = world, map = world,
    alpha = 0.6,
    aes(long, lat, map_id = region)
  ) + 
  scale_y_continuous(breaks=NULL) +
  scale_x_continuous(breaks=NULL) + 
  theme(panel.background = element_rect(fill='white', colour='white'))
  

# bin the hotspot into hexagons
makeHexData <- function(df, nbins, xbnds, ybnds) {

 h <- hexbin(df$lng, df$lat, nbins, xbnds = xbnds, ybnds = ybnds, IDs = TRUE)
 data.frame(hcell2xy(h),
            count = tapply(df$hotspot, h@cID, FUN = function(z) length(z)), # calculate the number of row as the number of transactions
            cid = h@cell)
}

# find the bounds for the complete data
xbndsHotspot <- range(dataHotspots$lng)
ybndsHotspot <- range(dataHotspots$lat)
 
nHotspotsHexbin <- dataHotspots %>%
  group_modify(~ makeHexData(.x, nbins = 500, xbnds = xbndsHotspot, ybnds = ybndsHotspot))

map +
  geom_hex(aes(x = x, y = y, fill = count),
             stat = "identity", 
             alpha = 0.8,
             data = nHotspotsHexbin) +
    scale_fill_distiller(palette = "Spectral", trans = "log10") +
  labs(title = "Number of hotspots in the world",
       fill = "Number of hotspots") +
  theme(legend.position = "bottom")
```

Let's summaries the proportion of hotspot per continent. For this, we will leverage the *rworldmap* package with a custom function from [here](https://stackoverflow.com/questions/21708488/get-country-and-continent-from-longitude-and-latitude-point-in-r) to convert lng/lat into the continents.


```{r}
# The single argument to this function, points, is a data.frame in which:
#   - column 1 contains the longitude in degrees
#   - column 2 contains the latitude in degrees
coords2continent = function(points)
{  
  countriesSP <- getMap(resolution='low')

  # converting points to a SpatialPoints object setting CRS directly to that from rworldmap
  pointsSP = SpatialPoints(points, proj4string=CRS(proj4string(countriesSP)))  

  # use 'over' to get indices of the Polygons object containing each point 
  indices = over(pointsSP, countriesSP)

  return(data.frame(continent = indices$REGION, country = indices$ADMIN))
}

dataHotspots <- dataHotspots %>%
  mutate(coords2continent(data.frame(.$lng, .$lat)),
         continent = replace_na(as.character(continent), "Undefined"))

dataHotspots %>%
  group_by(continent) %>%
  summarise(count = n()) %>%
  mutate(percentage = round(count/sum(count)*100,2)) %>%
  arrange(desc(count)) %>%
  kable(caption = "Table 2: Proportion of hotspot per continent.")
```


# Packet data

Now, that these hotspots exist, we would like to know if they are useful. Are they used by connected device to transfer data? How often?

To answer this question, we download all the history of data transfer. This is a huge dataset (3GB). On Helium, you only pay data you use. Every 24 bytes sent in an uplink or downlink packet cost 1 Data Credit (DC) = $0.00001. To get an idea of how much the network is used, we can summarise from 2 perspectives: (1) calculate the size of the volume of data exchanged and (2) calculate how often the hotspots are used by the devices.

```{r}
### Retrieve transferred data packed data
listFilesPackets <- list.files("data/packets", pattern=".csv.gz", recursive = T)

# We specify the columns we want to keep directly in the fread call to save memory
dataPackets <- lapply(1:length(listFilesPackets),function(i){
# dataPackets <- lapply(1:6,function(i){

  data <- fread(file = paste0("data/packets/",listFilesPackets[i]), select = c("block", "transaction_hash", "time", "gateway", "num_dcs")) 
  
  return(data)
})

dataPackets <- dplyr::bind_rows(dataPackets) %>%
  mutate(bytes = 24 * num_dcs, # Every 24 bytes sent in an uplink or downlink packet cost 1 DC = $.00001.
         date = as.POSIXct(time, origin = "1970-01-01"),
         date = ceiling_date(date, "day")) %>% # reduce the precision of the date to ease the plotting
  mutate_at(c("transaction_hash", "gateway"), as.factor) %>%
  select(-time, -num_dcs) %>%
  rename(hotspot = gateway) 

# let's combine the hotspot and packet dataset by keeping all rows X and Y
## we do this little trick with factor to avoid dropping hotspots not involved in any transaction 
combined <- sort(union(levels(dataPackets$hotspot), levels(dataHotspots$hotspot)))
dataPackets <- dataPackets %>% mutate(hotspot = factor(hotspot, levels = combined))
dataHotspots <- dataHotspots %>% mutate(hotspot = factor(hotspot, levels = combined))
dataPacketsWithLocation <- inner_join(dataPackets, dataHotspots) 
```

## Volume of data exchanged

The total volume exchanged between hotspot and connected device so far is calculated below. That's clearly very small (that's about the data volume I made with my smartphone in recent years) but this metric is not a good indication of the Helium usage. Indeed, the network is not intended to transfer huge volume of data but to transfer data on long distance and for a cheap price. Any comparison with any other data transfer technology would not make sense. Let's check another metric.
```{r}
paste(round(sum(dataPacketsWithLocation$bytes) / 1e+12,3), "TB") # sum and convert Byte to Terabyte
```


## Number of transactions

Each data transfer between a hotspot and a device corresponds to one transaction on the blockchain. To summarise this, we simply need to count the row to determine the number of transactions. The plot is very similar to the plot above for the number of hotspot: a slow linear phase followed by an exponential and then a fast linear phases (but what is this glitch?).

```{r, out.width = '75%'}
nTransactionsPerDate <- dataPacketsWithLocation %>%
  group_by(date) %>%
  summarise(numberOfTransactions = n())

ggplot(nTransactionsPerDate, aes(x = date, y = cumsum(numberOfTransactions))) +
  geom_line() +
  labs(title = "Growth of the number of data transfer between hotspots and devices", 
       y = "Total number of data transfer",
       x = "Date") +
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE))
```

As we did above, we can plot the world map, bin the data using the *makeHexData* function and overlay with the number of data transactions. This time, let's create an animation using the *gganimate* package. Surprisingly, although we saw there are a lot of hotspots in Asia, they don't seem to be used much to transfer data in contrast to North America and Europe.

```{r}
## bin the hotspot into hexagons
# find the bounds for the complete data
xbndsPacket <- range(dataPacketsWithLocation$lng)
ybndsPacket <- range(dataPacketsWithLocation$lat)
 
nTransactionsPerDateHexbin <- dataPacketsWithLocation %>%
  mutate(date = ceiling_date(date, "week")) %>% # let's decrease the resolution to ease plotting
  group_by(date) %>% 
  group_modify(~ makeHexData(.x, nbins = 100, xbnds = xbndsPacket, ybnds = ybndsPacket))

pNumberOfTransactionsAnimated <- map +
  geom_hex(aes(x = x, y = y, fill = count),
             stat = "identity", 
             alpha = 0.8,
             data = nTransactionsPerDateHexbin) +
    scale_fill_distiller(palette = "Spectral", trans = "log10") +
  labs(title = "Evolution of the number of transactions",
       fill = "Number of transactions") +
  theme(legend.position = "bottom")

anim <- pNumberOfTransactionsAnimated + 
  transition_states(date) +
  labs(title = "Date: {closest_state}",
          subtitle = 'Frame {frame} of {nframes}') 

animate(anim, nframes = length(unique(nTransactionsPerDateHexbin$date)))
```

This is confirmed by the proportion of transaction as a function of the continent, we see Asia represents only 3% of the total.

```{r}
dataPacketsWithLocation %>%
  group_by(continent) %>%
  summarise(count = n()) %>%
  mutate(percentage = round(count/sum(count)*100,2)) %>%
  arrange(desc(count)) %>%
  kable(caption = "Table 3: Proportion of transactions per continent.")
```

Now we might wonder what proportion of hotspots are involved in transactions and what is the average number of transactions.
```{r}
summaryTransactionPerHotspot <- dataPacketsWithLocation %>%
  group_by(hotspot, .drop = FALSE) %>%
  summarise(count = n())

medianNumberOfTransactions <- median(summaryTransactionPerHotspot$count)
propWith0Transactions <- (length(which(summaryTransactionPerHotspot$count == 0)) / length(combined)) * 100
```

The median number of transaction per hotspot is `r medianNumberOfTransactions` and only `r round(propWith0Transactions, 2)`% hotspots did not participate in any transaction so far. We can say that all hotspots are useful!

To add a bit of fun, we can also turn the plot in 3D. Let's focus on two countries: US as it has the biggest number of hotspot and transactions and Belgium, which is my home country. We have to rebin the data since we won't generate an animation (but that's possible, see [this](https://ghanadatastuff.com/post/3d_population_density/)).

This is US:

```{r}
# regenerate the map but subset on US
US <- map_data("usa")
mapUS <- ggplot() +
  geom_map(
    data = US, map = US,
    alpha = 0.6,
    aes(long, lat, map_id = region)
  ) + 
  scale_y_continuous(breaks=NULL) +
  scale_x_continuous(breaks=NULL) + 
  theme(panel.background = element_rect(fill='white', colour='white'))

# filter to keep only US transactions
dataPacketsWithLocationUS <- dataPacketsWithLocation %>%
  filter(country == "United States of America") %>% 
  filter(lng > -140) # there are a few hotspots far from the mainland

# find the bounds for the complete data
xbndsPacketUS <- range(dataPacketsWithLocationUS$lng)
ybndsPacketUS <- range(dataPacketsWithLocationUS$lat)

# bin onto hexagons
nTransactionsUS <- dataPacketsWithLocationUS %>%
  group_modify(~ makeHexData(.x, nbins = 250, xbnds = xbndsPacketUS, ybnds = ybndsPacketUS))

# generate the plot
pNumberOfTransactionsUS <- mapUS +
  geom_hex(aes(x = x, y = y, fill = count),
             stat = "identity", 
             alpha = 0.8,
             data = nTransactionsUS) +
    scale_fill_distiller(palette = "Spectral", trans = "log10") +
  labs(title = "Number of transactions",
       fill = "Number of transactions") +
  theme(legend.position = "bottom")

# add the 3D
plot_gg(pNumberOfTransactionsUS, 
        multicore = TRUE, 
        width = 5,
        height= 5, 
        zoom = 0.7, 
        theta = 25, 
        phi = 50)
# render_snapshot()
rglwidget()
```

This is Belgium:

```{r}
# # Get the world map
# BE <- world %>% filter(region == "Belgium")
# 
# mapBE <- ggplot() +
#   geom_map(
#     data = BE, map = BE,
#     alpha = 0.6,
#     aes(long, lat, map_id = region)
#   ) + 
#   scale_y_continuous(breaks=NULL) +
#   scale_x_continuous(breaks=NULL) + 
#   theme(panel.background = element_rect(fill='white', colour='white'))
# 
# # filter to keep only US transactions
# dataPacketsWithLocationBE <- dataPacketsWithLocation %>%
#   filter(country == "Belgium") 
# 
# # find the bounds for the complete data
# xbndsPacketBE <- range(dataPacketsWithLocationBE$lng)
# ybndsPacketBE <- range(dataPacketsWithLocationBE$lat)
# 
# # bin onto hexagons
# nTransactionsBE <- dataPacketsWithLocationBE %>%
#   group_modify(~ makeHexData(.x, nbins = 500, xbnds = xbndsPacketBE, ybnds = ybndsPacketBE))
# 
# # generate the plot
# pNumberOfTransactionsBE <- mapBE +
#   geom_hex(aes(x = x, y = y, fill = count),
#              stat = "identity", 
#              alpha = 0.8,
#              data = nTransactionsBE) +
#     scale_fill_distiller(palette = "Spectral", trans = "log10") +
#   labs(title = "Total number of transactions in Belgium",
#        fill = "Number of transactions") +
#   theme(legend.position = "bottom")
# 
# # add the 3D
# plot_gg(pNumberOfTransactionsBE, 
#         multicore = TRUE, 
#         width = 6,
#         height= 5, 
#         fov = 70)
```

I'd like to thank the Helium Discord community (#data-analysis) for helping me understanding the dataset as well as the Dewi team for providing the data.

If you wish to help us continue researching and writing about data science on blockchain, don't hesitate to make a donation to our Ethereum address (0xf5fC137E7428519969a52c710d64406038319169) or Tezos address (tz1ffZLHbu9adcobxmd411ufBDcVgrW14mBd).

# References

<https://datavizpyr.com/how-to-make-world-map-with-ggplot2-in-r/>
<https://docs.helium.com/>
<https://www.rayshader.com/>
<https://explorer.helium.com/>
